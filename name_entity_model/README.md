# NER (Named Entity Recognition) ä¸­æ–‡å‘½åå¯¦é«”è­˜åˆ¥æ¨¡çµ„

## ğŸ“‹ å°ˆæ¡ˆç°¡ä»‹

é€™æ˜¯ä¸€å€‹åŸºæ–¼BERTçš„ä¸­æ–‡å‘½åå¯¦é«”è­˜åˆ¥ï¼ˆNERï¼‰æ¨¡çµ„ï¼Œå°ˆé–€ç”¨æ–¼è­˜åˆ¥ä¸­æ–‡æ–‡æœ¬ä¸­çš„äººåã€‚è©²å°ˆæ¡ˆå°‡åŸæœ¬çš„Jupyter Notebooké‡æ§‹ç‚ºæ¨™æº–çš„Pythonæ¨¡çµ„ï¼Œæä¾›äº†å®Œæ•´çš„è¨“ç·´å’Œé æ¸¬ç®¡é“ã€‚

### âœ¨ ä¸»è¦ç‰¹æ€§

- ğŸ¤– åŸºæ–¼BERTçš„æ·±åº¦å­¸ç¿’æ¨¡å‹
- ğŸ¯ å°ˆé–€é‡å°ä¸­æ–‡äººåè­˜åˆ¥å„ªåŒ–
- ğŸ“Š å®Œæ•´çš„è¨“ç·´å’Œè©•ä¼°æµç¨‹
- ğŸš€ æ”¯æŒæ‰¹é‡é æ¸¬å’Œäº¤äº’å¼é æ¸¬
- ğŸ“ˆ æä¾›è¨“ç·´å¯è¦–åŒ–å’ŒæŒ‡æ¨™ç›£æ§
- ğŸ”§ æ¨¡çµ„åŒ–è¨­è¨ˆï¼Œæ˜“æ–¼æ“´å±•å’Œç¶­è­·

## ğŸ—ï¸ å°ˆæ¡ˆçµæ§‹

```
name_entity_model/
â”œâ”€â”€ __init__.py           # æ¨¡çµ„åˆå§‹åŒ–æ–‡ä»¶
â”œâ”€â”€ config.py             # é…ç½®æ–‡ä»¶
â”œâ”€â”€ data_loader.py        # æ•¸æ“šåŠ è¼‰å’Œé è™•ç†
â”œâ”€â”€ model.py              # æ¨¡å‹å®šç¾©
â”œâ”€â”€ trainer.py            # è¨“ç·´é‚è¼¯
â”œâ”€â”€ predictor.py          # é æ¸¬é‚è¼¯
â”œâ”€â”€ utils.py              # å·¥å…·å‡½æ•¸
â”œâ”€â”€ train.py              # è¨“ç·´ä¸»ç¨‹åº
â”œâ”€â”€ predict.py            # é æ¸¬ä¸»ç¨‹åº
â”œâ”€â”€ requirements.txt      # ä¾è³´æ–‡ä»¶
â””â”€â”€ README.md            # èªªæ˜æ–‡æª”
```

## ğŸš€ å¿«é€Ÿé–‹å§‹

### 1. ç’°å¢ƒå®‰è£

```bash
# å®‰è£ä¾è³´
pip install -r requirements.txt
```

### 2. æº–å‚™æ•¸æ“š

ç¢ºä¿ä½ çš„æ•¸æ“šæ–‡ä»¶ä½æ–¼æ­£ç¢ºçš„ä½ç½®ï¼š
```
data/äºæ´²ç ”ç©¶é™¢æ•¸æ“šé›†/asia_institute.csv
```

æ•¸æ“šæ ¼å¼æ‡‰åŒ…å« `words` å’Œ `tags_encoding` åˆ—ã€‚

### 3. è¨“ç·´æ¨¡å‹

#### ä½¿ç”¨å‘½ä»¤è¡Œè¨“ç·´

```bash
# åŸºæœ¬è¨“ç·´
python train.py

# è‡ªå®šç¾©åƒæ•¸è¨“ç·´
python train.py --epochs 5 --batch_size 16 --learning_rate 2e-5 --early_stopping --plot_training
```

#### ä½¿ç”¨Pythonä»£ç¢¼è¨“ç·´

```python
from name_entity_model import train_ner_model, create_data_loaders, create_ner_model

# åŠ è¼‰æ•¸æ“š
train_dl, valid_dl, data_info = create_data_loaders()

# å‰µå»ºæ¨¡å‹
model = create_ner_model()

# è¨“ç·´
trainer, trained_model = train_ner_model(
    train_dataloader=train_dl,
    valid_dataloader=valid_dl,
    model=model,
    epochs=3
)
```

### 4. ä½¿ç”¨æ¨¡å‹é æ¸¬

#### å‘½ä»¤è¡Œé æ¸¬

```bash
# å–®å€‹æ–‡æœ¬é æ¸¬
python predict.py --text "å¼µå®‰æ¨‚æ˜¯ä¸­è¯çµ±ä¸€ä¿ƒé€²é»¨ç¸½è£"

# æ‰¹é‡æ–‡ä»¶é æ¸¬
python predict.py --input_file input.csv --output_file output.json

# äº¤äº’å¼é æ¸¬
python predict.py
```

#### Pythonä»£ç¢¼é æ¸¬

```python
from name_entity_model import create_predictor

# å‰µå»ºé æ¸¬å™¨
predictor = create_predictor("model/ner_model_weights.pth")

# é æ¸¬äººå
text = "å¼µå®‰æ¨‚åŠå…¶å­å¼µç‘‹ï¼Œé­æ§æ”¶å—æ”¿æ²»ç»é‡‘"
names = predictor.extract_names(text)
print(names)  # ['å¼µå®‰æ¨‚', 'å¼µç‘‹']

# ç²å–å®Œæ•´å¯¦é«”ä¿¡æ¯
entities = predictor.extract_entities(text, return_positions=True)
print(entities)
```

## ğŸ“– è©³ç´°ä½¿ç”¨èªªæ˜

### é…ç½®åƒæ•¸

ä¸»è¦é…ç½®åƒæ•¸åœ¨ `config.py` ä¸­å®šç¾©ï¼š

```python
# æ¨¡å‹é…ç½®
MODEL_NAME = "bert-base-chinese"
MAX_LEN = 75
BATCH_SIZE = 32
EPOCHS = 3
LEARNING_RATE = 3e-5

# æ¨™ç±¤é…ç½®
TAG_VALUES = ['O', 'B_person_name', 'M_person_name', 'E_person_name', 'PAD']
```

### è¨“ç·´åƒæ•¸

è¨“ç·´è…³æœ¬æ”¯æŒçš„ä¸»è¦åƒæ•¸ï¼š

```bash
python train.py --help

optional arguments:
  --data_file           è¨“ç·´æ•¸æ“šæ–‡ä»¶è·¯å¾‘
  --model_name          é è¨“ç·´æ¨¡å‹åç¨±
  --epochs              è¨“ç·´è¼ªæ•¸
  --batch_size          æ‰¹æ¬¡å¤§å°
  --learning_rate       å­¸ç¿’ç‡
  --early_stopping      ä½¿ç”¨æ—©åœæ©Ÿåˆ¶
  --plot_training       ç¹ªè£½è¨“ç·´æ›²ç·š
  --output_dir          æ¨¡å‹ä¿å­˜ç›®éŒ„
```

### é æ¸¬åƒæ•¸

é æ¸¬è…³æœ¬æ”¯æŒçš„ä¸»è¦åƒæ•¸ï¼š

```bash
python predict.py --help

optional arguments:
  --model_path          è¨“ç·´å¥½çš„æ¨¡å‹æ¬Šé‡è·¯å¾‘
  --text                è¦é æ¸¬çš„å–®å€‹æ–‡æœ¬
  --input_file          åŒ…å«å¤šå€‹æ–‡æœ¬çš„è¼¸å…¥æ–‡ä»¶
  --output_file         é æ¸¬çµæœè¼¸å‡ºæ–‡ä»¶è·¯å¾‘
  --names_only          åªè¿”å›äººååˆ—è¡¨
  --batch_size          æ‰¹é‡é æ¸¬çš„æ‰¹æ¬¡å¤§å°
```

## ğŸ“Š æ¨¡å‹æ€§èƒ½

åŸºæ–¼äºæ´²ç ”ç©¶é™¢æ•¸æ“šé›†çš„æ¸¬è©¦çµæœï¼š

- **æº–ç¢ºç‡ (Accuracy)**: ~99.8%
- **F1åˆ†æ•¸**: ~97.2%
- **è¨“ç·´æ™‚é–“**: ~9åˆ†é˜ï¼ˆ3å€‹epochï¼ŒRTX 4070 SUPERï¼‰

## ğŸ› æ•…éšœæ’é™¤

### å¸¸è¦‹å•é¡Œ

1. **CUDA out of memory**
   - æ¸›å°‘ `BATCH_SIZE` åƒæ•¸
   - æ¸›å°‘ `MAX_LEN` åƒæ•¸

2. **æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨**
   - ç¢ºä¿æ¨¡å‹å·²ç¶“è¨“ç·´å®Œæˆ
   - æª¢æŸ¥æ¨¡å‹è·¯å¾‘æ˜¯å¦æ­£ç¢º

3. **æ•¸æ“šæ ¼å¼éŒ¯èª¤**
   - ç¢ºä¿CSVæ–‡ä»¶åŒ…å« `words` å’Œ `tags_encoding` åˆ—
   - æª¢æŸ¥æ•¸æ“šæ˜¯å¦ç‚ºæ­£ç¢ºçš„åˆ—è¡¨æ ¼å¼


## ğŸ“„ æˆæ¬Š

æœ¬å°ˆæ¡ˆä½¿ç”¨ MIT æˆæ¬Šæ¢æ¬¾ã€‚

### é–‹ç™¼ç’°å¢ƒè¨­ç½®

```bash
# Clone project
git clone <repository-url>
cd name_entity_model

# å®‰è£é–‹ç™¼ä¾è³´
pip install -r requirements.txt

```