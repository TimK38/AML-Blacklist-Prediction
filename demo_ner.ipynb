{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1253c2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功加載數據，共 50091 條記錄\n",
      "訓練數據: 45081 條\n",
      "驗證數據: 5010 條\n",
      "訓練批次數: 1409\n",
      "驗證批次數: 157\n"
     ]
    }
   ],
   "source": [
    "from name_entity_model import train_ner_model, create_data_loaders, create_ner_model\n",
    "\n",
    "# 加載數據\n",
    "train_dl, valid_dl, data_info = create_data_loaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "221d528a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功創建模型: bert-base-chinese\n",
      "標籤數量: 5\n",
      "設備: cuda\n",
      "優化器設置完成，總訓練步數: 4227\n",
      "開始訓練，共 3 個epoch\n",
      "訓練設備: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 0.014469254511897468\n",
      "Validation loss: 0.0022798286544034483\n",
      "Validation Accuracy: 0.9968\n",
      "Validation F1-Score: 0.9548\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  33%|███▎      | 1/3 [02:47<05:35, 167.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型已保存到: c:\\Users\\User\\Tim\\AML-Blacklist-Prediction\\model\\ner_model_weights.pth\n",
      "保存最佳模型，F1-Score: 0.9548\n",
      "Validation loss: 0.002280\n",
      "Average train loss: 0.0016912967001782386\n",
      "Validation loss: 0.001970635212792389\n",
      "Validation Accuracy: 0.9975\n",
      "Validation F1-Score: 0.9661\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  67%|██████▋   | 2/3 [05:35<02:47, 167.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型已保存到: c:\\Users\\User\\Tim\\AML-Blacklist-Prediction\\model\\ner_model_weights.pth\n",
      "保存最佳模型，F1-Score: 0.9661\n",
      "Validation loss improved: 0.001971\n",
      "Average train loss: 0.0007263104409653039\n",
      "Validation loss: 0.0019291856196638024\n",
      "Validation Accuracy: 0.9979\n",
      "Validation F1-Score: 0.9736\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 3/3 [08:21<00:00, 167.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型已保存到: c:\\Users\\User\\Tim\\AML-Blacklist-Prediction\\model\\ner_model_weights.pth\n",
      "保存最佳模型，F1-Score: 0.9736\n",
      "Validation loss improved: 0.001929\n",
      "訓練完成！最佳F1-Score: 0.9736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 創建模型\n",
    "model = create_ner_model()\n",
    "\n",
    "# 訓練\n",
    "trainer, trained_model = train_ner_model(\n",
    "    train_dataloader=train_dl,\n",
    "    valid_dataloader=valid_dl,\n",
    "    model=model,\n",
    "    epochs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2e1d328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分詞器加載成功\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功創建模型: bert-base-chinese\n",
      "標籤數量: 5\n",
      "設備: cuda\n",
      "成功加載模型權重: model/ner_model_weights.pth\n",
      "模型加載成功: model/ner_model_weights.pth\n",
      "['張安樂', '張瑋']\n",
      "[{'text': '張安樂', 'tokens': ['張', '安', '樂'], 'label': 'person_name', 'confidence': [0.9999178647994995, 0.9998550415039062, 0.999894380569458], 'start_idx': 0, 'end_idx': 2, 'avg_confidence': 0.999889095624288, 'min_confidence': 0.9998550415039062, 'max_confidence': 0.9999178647994995}, {'text': '張瑋', 'tokens': ['張', '瑋'], 'label': 'person_name', 'confidence': [0.9997852444648743, 0.9994761347770691], 'start_idx': 6, 'end_idx': 7, 'avg_confidence': 0.9996306896209717, 'min_confidence': 0.9994761347770691, 'max_confidence': 0.9997852444648743}]\n"
     ]
    }
   ],
   "source": [
    "from name_entity_model import create_predictor\n",
    "\n",
    "# 創建預測器\n",
    "predictor = create_predictor(\"model/ner_model_weights.pth\")\n",
    "\n",
    "# 預測人名\n",
    "text = \"張安樂及其子張瑋，遭控收受政治獻金\"\n",
    "names = predictor.extract_names(text)\n",
    "print(names)  # ['張安樂', '張瑋']\n",
    "\n",
    "# 獲取完整實體信息\n",
    "entities = predictor.extract_entities(text, return_positions=True)\n",
    "print(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf16f15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deepseek",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
